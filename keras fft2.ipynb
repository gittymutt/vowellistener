{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/deploying-a-simple-machine-learning-model-into-a-webapp-using-tensorflow-js-3609c297fb04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 15 12:22:16 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 451.67       Driver Version: 451.67       CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 105... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   44C    P8    N/A /  N/A |     75MiB /  4096MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1680    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A      4368    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A      5472    C+G   ...8wekyb3d8bbwe\\GameBar.exe    N/A      |\n",
      "|    0   N/A  N/A      6676    C+G   ...wekyb3d8bbwe\\Music.UI.exe    N/A      |\n",
      "|    0   N/A  N/A      9120    C+G   ...ekyb3d8bbwe\\commsapps.exe    N/A      |\n",
      "|    0   N/A  N/A     10264    C+G   ...\\atom\\app-1.53.0\\atom.exe    N/A      |\n",
      "|    0   N/A  N/A     11960    C+G   ...nputApp\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     13540    C+G   ...4__8j3eq9eme6ctt\\IGCC.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the dataset       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_data(filename):\n",
    "    path = 'fft_data/'\n",
    "    with open(path + filename, 'r') as myfile:\n",
    "        data=myfile.read()\n",
    "\n",
    "    obj = json.loads(data)\n",
    "\n",
    "\n",
    "    for fft in obj:\n",
    "        dataset.append((fft['vowel'], np.array(fft['FFT'], dtype=np.uint8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = [\"ae_fft_data.txt\",\n",
    "              \"ah_fft_data.txt\",\n",
    "              \"book_fft_data.txt\",\n",
    "              \"ee_fft_data.txt\",\n",
    "              \"eh_fft_data.txt\",\n",
    "              \"er_fft_data.txt\",\n",
    "              \"ih_fft_data.txt\",\n",
    "              \"oo_fft_data.txt\",\n",
    "              \"uh_fft_data.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in file_names:\n",
    "    add_data(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4586"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "path = 'fft_data'\n",
    "with open(path + '/ee_fft_data.txt', 'r') as myfile:\n",
    "    data=myfile.read()\n",
    "\n",
    "obj = json.loads(data)\n",
    "\n",
    "\n",
    "for fft in obj:\n",
    "   dataset.append((fft['vowel'], np.array(fft['FFT'], dtype=np.uint8)))\n",
    "   \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "path = 'fft_data'\n",
    "with open(path + '/ih_fft_data.txt', 'r') as myfile:\n",
    "    data=myfile.read()\n",
    "\n",
    "obj = json.loads(data)\n",
    "\n",
    "\n",
    "for fft in obj:\n",
    "   dataset.append((fft['vowel'], np.array(fft['FFT'], dtype=np.uint8)))\n",
    "   \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dataset = [vowel for vowel, fft in dataset]\n",
    "x_dataset = [fft for vowel, fft in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to numpy arrays and reshape training data for tf\n",
    "x_dataset = np.array(x_dataset)\n",
    "x_dataset = x_dataset.reshape(len(x_dataset),512,1).astype('float32')\n",
    "\n",
    "y_dataset = np.array(y_dataset).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split in to train and test\n",
    "cutoff = round(len(y_dataset)*0.8) # 80/20 split\n",
    "X_train = x_dataset[:cutoff]\n",
    "y_train = y_dataset[:cutoff]\n",
    "X_test = x_dataset[cutoff:]\n",
    "y_test = y_dataset[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4586, 3669, 917, 4586)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_dataset), len(X_train), len(X_test), len(X_train)+len(X_test)\n",
    "len(y_dataset), len(y_train), len(y_test), len(y_train)+len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# flatten 28*28 images to a 784 vector for each image\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')\n",
    "\n",
    "\n",
    "#X_train = X_train.reshape((X_train.shape[0], 28, 28, 1)).astype('float32')\n",
    "#X_test = X_test.reshape((X_test.shape[0], 28, 28, 1)).astype('float32')\n",
    "\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "# one hot encode outputs\n",
    "#y_train = np_utils.to_categorical(y_train)\n",
    "#y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 0.2046 - accuracy: 0.6446\n",
      "Epoch 2/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 0.0865 - accuracy: 0.8820\n",
      "Epoch 3/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 0.0499 - accuracy: 0.9395\n",
      "Epoch 4/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 0.0340 - accuracy: 0.9621\n",
      "Epoch 5/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 0.0229 - accuracy: 0.9768\n",
      "Epoch 6/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 0.0179 - accuracy: 0.9793\n",
      "Epoch 7/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 0.0159 - accuracy: 0.9836\n",
      "Epoch 8/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 0.0099 - accuracy: 0.9921\n",
      "Epoch 9/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 0.0061 - accuracy: 0.9945\n",
      "Epoch 10/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 0.0081 - accuracy: 0.9943\n",
      "Epoch 11/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 0.0099 - accuracy: 0.9913\n",
      "Epoch 12/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 0.0030 - accuracy: 0.9986\n",
      "Epoch 13/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 0.0048 - accuracy: 0.9945\n",
      "Epoch 14/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 0.0111 - accuracy: 0.9910\n",
      "Epoch 15/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 0.0019 - accuracy: 0.9981\n",
      "Epoch 16/150\n",
      "367/367 [==============================] - 1s 3ms/step - loss: 0.0017 - accuracy: 0.9992\n",
      "Epoch 17/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 0.0011 - accuracy: 0.9992\n",
      "Epoch 18/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 0.0139 - accuracy: 0.9817\n",
      "Epoch 19/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 0.0054 - accuracy: 0.9937\n",
      "Epoch 20/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 0.0011 - accuracy: 0.9992\n",
      "Epoch 21/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 6.3561e-04 - accuracy: 0.9997\n",
      "Epoch 22/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 9.9115e-04 - accuracy: 0.9992\n",
      "Epoch 23/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 6.5003e-04 - accuracy: 0.9997\n",
      "Epoch 24/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 4.6871e-04 - accuracy: 0.9997\n",
      "Epoch 25/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 0.0116 - accuracy: 0.9853\n",
      "Epoch 26/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 0.0099 - accuracy: 0.9866\n",
      "Epoch 27/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 0.0014 - accuracy: 0.9989\n",
      "Epoch 28/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 7.7518e-04 - accuracy: 0.9995\n",
      "Epoch 29/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 2.9282e-04 - accuracy: 1.0000\n",
      "Epoch 30/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 0.0024 - accuracy: 0.9978\n",
      "Epoch 31/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 3.0971e-04 - accuracy: 1.0000\n",
      "Epoch 32/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 1.6110e-04 - accuracy: 1.0000\n",
      "Epoch 33/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 1.0641e-04 - accuracy: 1.0000\n",
      "Epoch 34/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 8.7403e-05 - accuracy: 1.0000\n",
      "Epoch 35/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 6.8570e-05 - accuracy: 1.0000\n",
      "Epoch 36/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 0.0191 - accuracy: 0.9787\n",
      "Epoch 37/150\n",
      "367/367 [==============================] - 1s 3ms/step - loss: 0.0023 - accuracy: 0.9978\n",
      "Epoch 38/150\n",
      "367/367 [==============================] - 1s 3ms/step - loss: 0.0051 - accuracy: 0.9921\n",
      "Epoch 39/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 7.0316e-04 - accuracy: 0.9992\n",
      "Epoch 40/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 1.6324e-04 - accuracy: 1.0000\n",
      "Epoch 41/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 9.5075e-05 - accuracy: 1.0000\n",
      "Epoch 42/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 7.2277e-05 - accuracy: 1.0000\n",
      "Epoch 43/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 5.4663e-05 - accuracy: 1.0000\n",
      "Epoch 44/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 4.4655e-05 - accuracy: 1.0000\n",
      "Epoch 45/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 3.7261e-05 - accuracy: 1.0000\n",
      "Epoch 46/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 3.1980e-05 - accuracy: 1.0000\n",
      "Epoch 47/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 2.7745e-05 - accuracy: 1.0000\n",
      "Epoch 48/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 2.3326e-05 - accuracy: 1.0000\n",
      "Epoch 49/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 1.9593e-05 - accuracy: 1.0000\n",
      "Epoch 50/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 1.7375e-05 - accuracy: 1.0000\n",
      "Epoch 51/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 0.0117 - accuracy: 0.9886\n",
      "Epoch 52/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 0.0044 - accuracy: 0.9962\n",
      "Epoch 53/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 0.0038 - accuracy: 0.9951\n",
      "Epoch 54/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 0.0028 - accuracy: 0.9962\n",
      "Epoch 55/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 4.8004e-04 - accuracy: 0.9997\n",
      "Epoch 56/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 8.4731e-05 - accuracy: 1.0000\n",
      "Epoch 57/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 5.8374e-05 - accuracy: 1.0000\n",
      "Epoch 58/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 3.9120e-05 - accuracy: 1.0000\n",
      "Epoch 59/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 2.9637e-05 - accuracy: 1.0000\n",
      "Epoch 60/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 2.4075e-05 - accuracy: 1.0000\n",
      "Epoch 61/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 1.9686e-05 - accuracy: 1.0000\n",
      "Epoch 62/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 1.6704e-05 - accuracy: 1.0000\n",
      "Epoch 63/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 1.3872e-05 - accuracy: 1.0000\n",
      "Epoch 64/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 1.1810e-05 - accuracy: 1.0000\n",
      "Epoch 65/150\n",
      "367/367 [==============================] - 1s 3ms/step - loss: 1.0553e-05 - accuracy: 1.0000\n",
      "Epoch 66/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 8.5487e-06 - accuracy: 1.0000\n",
      "Epoch 67/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 7.1941e-06 - accuracy: 1.0000\n",
      "Epoch 68/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 6.3877e-06 - accuracy: 1.0000\n",
      "Epoch 69/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 5.4234e-06 - accuracy: 1.0000\n",
      "Epoch 70/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 4.4267e-06 - accuracy: 1.0000\n",
      "Epoch 71/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 7.4216e-06 - accuracy: 1.0000\n",
      "Epoch 72/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 0.0156 - accuracy: 0.9820\n",
      "Epoch 73/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 2.4000e-04 - accuracy: 1.0000\n",
      "Epoch 74/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 6.2411e-05 - accuracy: 1.0000\n",
      "Epoch 75/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 2.7333e-05 - accuracy: 1.0000\n",
      "Epoch 76/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 1.8419e-05 - accuracy: 1.0000\n",
      "Epoch 77/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 1.4607e-05 - accuracy: 1.0000\n",
      "Epoch 78/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 1.2311e-05 - accuracy: 1.0000\n",
      "Epoch 79/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/367 [==============================] - 1s 2ms/step - loss: 1.0090e-05 - accuracy: 1.0000\n",
      "Epoch 80/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 8.5628e-06 - accuracy: 1.0000\n",
      "Epoch 81/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 7.5560e-06 - accuracy: 1.0000\n",
      "Epoch 82/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 6.2934e-06 - accuracy: 1.0000\n",
      "Epoch 83/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 5.5778e-06 - accuracy: 1.0000\n",
      "Epoch 84/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 4.6722e-06 - accuracy: 1.0000\n",
      "Epoch 85/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 4.1135e-06 - accuracy: 1.0000\n",
      "Epoch 86/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 3.6750e-06 - accuracy: 1.0000\n",
      "Epoch 87/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 3.1320e-06 - accuracy: 1.0000\n",
      "Epoch 88/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 2.7563e-06 - accuracy: 1.0000\n",
      "Epoch 89/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 2.4440e-06 - accuracy: 1.0000\n",
      "Epoch 90/150\n",
      "367/367 [==============================] - 1s 3ms/step - loss: 2.0569e-06 - accuracy: 1.0000\n",
      "Epoch 91/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 1.7606e-06 - accuracy: 1.0000\n",
      "Epoch 92/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 1.5591e-06 - accuracy: 1.0000\n",
      "Epoch 93/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 1.3934e-06 - accuracy: 1.0000\n",
      "Epoch 94/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 1.1345e-06 - accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 1.3174e-06 - accuracy: 1.0000\n",
      "Epoch 96/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 9.6305e-07 - accuracy: 1.0000\n",
      "Epoch 97/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 7.2773e-07 - accuracy: 1.0000\n",
      "Epoch 98/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 6.6404e-07 - accuracy: 1.0000\n",
      "Epoch 99/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 5.9164e-07 - accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 5.1217e-07 - accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 3.9278e-07 - accuracy: 1.0000\n",
      "Epoch 102/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 3.4999e-07 - accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 3.0261e-07 - accuracy: 1.0000\n",
      "Epoch 104/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 0.0204 - accuracy: 0.9842\n",
      "Epoch 105/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 1.2352e-04 - accuracy: 1.0000\n",
      "Epoch 106/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 2.8179e-05 - accuracy: 1.0000\n",
      "Epoch 107/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 1.8993e-05 - accuracy: 1.0000\n",
      "Epoch 108/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 1.2405e-05 - accuracy: 1.0000\n",
      "Epoch 109/150\n",
      "367/367 [==============================] - 1s 3ms/step - loss: 7.7090e-06 - accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 5.5121e-06 - accuracy: 1.0000\n",
      "Epoch 111/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 4.2243e-06 - accuracy: 1.0000\n",
      "Epoch 112/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 3.4524e-06 - accuracy: 1.0000\n",
      "Epoch 113/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 3.0674e-06 - accuracy: 1.0000\n",
      "Epoch 114/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 2.6496e-06 - accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 2.3254e-06 - accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 2.0204e-06 - accuracy: 1.0000\n",
      "Epoch 117/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 1.8122e-06 - accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 1.5932e-06 - accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 1.4317e-06 - accuracy: 1.0000\n",
      "Epoch 120/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 1.2617e-06 - accuracy: 1.0000\n",
      "Epoch 121/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 1.1400e-06 - accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 9.7822e-07 - accuracy: 1.0000\n",
      "Epoch 123/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 8.7884e-07 - accuracy: 1.0000\n",
      "Epoch 124/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 7.7145e-07 - accuracy: 1.0000\n",
      "Epoch 125/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 7.0555e-07 - accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 6.3803e-07 - accuracy: 1.0000\n",
      "Epoch 127/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 5.4473e-07 - accuracy: 1.0000\n",
      "Epoch 128/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 5.0148e-07 - accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 4.4296e-07 - accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 3.9180e-07 - accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 3.6366e-07 - accuracy: 1.0000\n",
      "Epoch 132/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 3.1079e-07 - accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "367/367 [==============================] - 1s 3ms/step - loss: 2.7337e-07 - accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "367/367 [==============================] - 1s 3ms/step - loss: 2.4524e-07 - accuracy: 1.0000\n",
      "Epoch 135/150\n",
      "367/367 [==============================] - 1s 3ms/step - loss: 2.1993e-07 - accuracy: 1.0000\n",
      "Epoch 136/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 1.9423e-07 - accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 1.6959e-07 - accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "367/367 [==============================] - 1s 3ms/step - loss: 1.4673e-07 - accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 1.2887e-07 - accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 1.1176e-07 - accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 1.0300e-07 - accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 1.0349e-07 - accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 0.0183 - accuracy: 0.9845\n",
      "Epoch 144/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 4.0726e-04 - accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "367/367 [==============================] - 1s 3ms/step - loss: 6.2789e-04 - accuracy: 0.9989\n",
      "Epoch 146/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 1.9997e-05 - accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 1.0927e-05 - accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 7.7003e-06 - accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 5.8453e-06 - accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "367/367 [==============================] - 1s 2ms/step - loss: 4.5697e-06 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25d85b927c0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=512, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(9, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 0s 1ms/step - loss: 3.8225e-06 - accuracy: 1.0000\n",
      "Accuracy: 100.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X_train, y_train)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.7087368e-09, 9.9999982e-01, 7.3769679e-09, 1.3336219e-16,\n",
       "        2.4026500e-10, 4.6997247e-16, 2.6492766e-12, 3.9615213e-09,\n",
       "        1.3273228e-17],\n",
       "       [3.2290740e-15, 7.9168931e-14, 1.0000000e+00, 2.1149218e-11,\n",
       "        2.0666512e-22, 2.0950751e-23, 4.2384801e-18, 9.0308793e-29,\n",
       "        1.3588356e-17],\n",
       "       [9.0588136e-17, 5.2090819e-12, 3.1707390e-08, 2.1502376e-04,\n",
       "        8.6303508e-01, 1.4876071e-08, 9.1791153e-04, 2.1435765e-08,\n",
       "        4.9057990e-11],\n",
       "       [4.2635091e-07, 9.9999976e-01, 1.5916039e-12, 6.5705955e-19,\n",
       "        5.4199845e-17, 8.6912158e-20, 1.8070698e-20, 4.8666220e-25,\n",
       "        3.2574362e-19],\n",
       "       [3.1053637e-19, 1.4497108e-16, 1.9005682e-26, 6.8289951e-10,\n",
       "        1.5442004e-21, 1.0000000e+00, 2.5987189e-27, 4.8877832e-22,\n",
       "        3.8056888e-10],\n",
       "       [2.1203308e-14, 8.5121297e-05, 9.9999398e-01, 1.2763224e-14,\n",
       "        6.4553221e-14, 5.0385804e-19, 2.3337809e-20, 4.2008470e-25,\n",
       "        5.3648510e-19],\n",
       "       [1.5298211e-17, 3.0905817e-14, 1.1472821e-01, 9.9997884e-01,\n",
       "        1.6330034e-12, 6.5613062e-18, 4.8291344e-07, 1.7822072e-18,\n",
       "        7.1440211e-12],\n",
       "       [1.0000000e+00, 1.3259356e-14, 2.0887636e-30, 2.6536725e-30,\n",
       "        8.4881571e-30, 5.5339671e-34, 5.4211425e-17, 5.8042561e-21,\n",
       "        4.3366483e-23],\n",
       "       [1.0000000e+00, 3.2418170e-19, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 1.7795696e-35, 0.0000000e+00,\n",
       "        0.0000000e+00],\n",
       "       [2.1044142e-16, 6.3105176e-07, 1.2645670e-15, 2.0503609e-11,\n",
       "        9.9975812e-01, 1.6151253e-14, 3.7735701e-04, 9.9398155e-12,\n",
       "        5.8572247e-14]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('fft_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be sure to save the converted model in the correct folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-17 21:37:01.493064: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found\n",
      "2020-11-17 21:37:01.493102: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!tensorflowjs_converter --input_format keras fft_model.h5 javascript\\model_fft_js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows\n",
      " Volume Serial Number is 9497-8F11\n",
      "\n",
      " Directory of C:\\Users\\pedro\\Documents\\programming\\python\\tf_fft\n",
      "\n",
      "11/15/2020  08:34 PM    <DIR>          .\n",
      "11/15/2020  08:34 PM    <DIR>          ..\n",
      "11/15/2020  01:26 PM    <DIR>          .ipynb_checkpoints\n",
      "11/15/2020  01:42 PM    <DIR>          fft_data\n",
      "11/15/2020  08:31 PM           106,328 fft_model.h5\n",
      "11/15/2020  01:15 PM    <DIR>          js_model\n",
      "11/15/2020  08:34 PM           287,004 keras fft.ipynb\n",
      "11/15/2020  01:14 PM           768,088 model.h5\n",
      "11/15/2020  01:09 PM                84 one-hot encoding key.txt\n",
      "               4 File(s)      1,161,504 bytes\n",
      "               5 Dir(s)  202,190,438,400 bytes free\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
